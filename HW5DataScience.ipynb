{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5DataScience",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPToJhUsb61iysfP7StA1Up",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmorkos/Jeffrey/blob/main/HW5DataScience.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsC2z3XD4ruh"
      },
      "source": [
        "gpu_boole = torch.cuda.is_available()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ylhUp2TFb3C"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels as sm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "988KItV21bil"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etZH17NqG-Te",
        "outputId": "f1d2da07-5fe8-4a02-96b5-aff82205a47f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "#Problem 1: Logistic Regression using Statsmodels\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv\")\n",
        "data = data.assign(x = (data.T2 - np.mean(data.T2)) / np.std(data.T2))\n",
        "def normalize(x):\n",
        "  return (x - np.mean(x)) / np.std(x)\n",
        "data=data.assign(y=(data.GOLD_Lesions))\n",
        "LR = smf.logit('y ~ x', data = data).fit()\n",
        "LR.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.687421\n",
            "         Iterations 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   100</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    98</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Mon, 05 Oct 2020</td> <th>  Pseudo R-squ.:     </th> <td>0.008262</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>00:33:55</td>     <th>  Log-Likelihood:    </th> <td> -68.742</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -69.315</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.2845</td> \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>    0.0005</td> <td>    0.201</td> <td>    0.002</td> <td> 0.998</td> <td>   -0.394</td> <td>    0.395</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x</th>         <td>    0.2159</td> <td>    0.204</td> <td>    1.061</td> <td> 0.289</td> <td>   -0.183</td> <td>    0.615</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   No. Observations:                  100\n",
              "Model:                          Logit   Df Residuals:                       98\n",
              "Method:                           MLE   Df Model:                            1\n",
              "Date:                Mon, 05 Oct 2020   Pseudo R-squ.:                0.008262\n",
              "Time:                        00:33:55   Log-Likelihood:                -68.742\n",
              "converged:                       True   LL-Null:                       -69.315\n",
              "Covariance Type:            nonrobust   LLR p-value:                    0.2845\n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept      0.0005      0.201      0.002      0.998      -0.394       0.395\n",
              "x              0.2159      0.204      1.061      0.289      -0.183       0.615\n",
              "==============================================================================\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65e8577oInug"
      },
      "source": [
        "#Problem 1 using PyTorch\n",
        "xtraining = torch.from_numpy(data['x'].values)\n",
        "ytraining = torch.from_numpy(data['y'].values)\n",
        "x_torch = xtraining.float()\n",
        "y_torch= ytraining.float()\n",
        "x_torch_training = x_torch.unsqueeze(1)\n",
        "y_torch_training= y_torch.unsqueeze(1)\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = torch.nn.Linear(1, 1, bias = True)\n",
        "  def forward(self, x):\n",
        "    y_pred_torch = torch.sigmoid(self.linear(x))\n",
        "    return y_pred_torch\n",
        "model=LogisticRegression()\n",
        "loss_function=torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "for i in range(100000):\n",
        "  y_torch=model(x_torch_training)\n",
        "  loss=loss_function(y_torch, y_torch_training)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77mpD7DyKbA5",
        "outputId": "9de14d90-2191-449d-aa36-c8944504325e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "#Comparing the two methods\n",
        "y_stats = 1 / (1 + np.exp(-LR.fittedvalues))\n",
        "y_torch_line=y_torch.detach().numpy().reshape(-1)\n",
        "plt.plot(y_stats, y_torch_line,  \".\")\n",
        "plt.plot([0, 1], [0, 1], linewidth=2)\n",
        "#The two models are really close when pytorch is allowed to iterate 100,000 times"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9092b89588>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_cVLAO5RZzZ",
        "outputId": "aff2665b-1636-4cac-d93d-4f4b29012f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "for x in model.parameters():\n",
        "  print(x)\n",
        "print(LR.summary())\n",
        "#same as listed above in the stats.models.summary"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.2159]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0005], requires_grad=True)\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   No. Observations:                  100\n",
            "Model:                          Logit   Df Residuals:                       98\n",
            "Method:                           MLE   Df Model:                            1\n",
            "Date:                Mon, 05 Oct 2020   Pseudo R-squ.:                0.008262\n",
            "Time:                        00:30:48   Log-Likelihood:                -68.742\n",
            "converged:                       True   LL-Null:                       -69.315\n",
            "Covariance Type:            nonrobust   LLR p-value:                    0.2845\n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept      0.0005      0.201      0.002      0.998      -0.394       0.395\n",
            "x              0.2159      0.204      1.061      0.289      -0.183       0.615\n",
            "==============================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMUXBOYfUfcE",
        "outputId": "feb0972e-8499-4787-c36b-a1fd9b01cca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "url='https://raw.githubusercontent.com/tidyverse/ggplot2/master/data-raw/diamonds.csv'\n",
        "data=pd.read_csv(url)\n",
        "list_of_data=[]\n",
        "categorical_columns=['color','clarity', 'cut']\n",
        "for i in categorical_columns:\n",
        "  data1=pd.get_dummies(data[i], drop_first=True)\n",
        "  list_of_data.append(data1)\n",
        "#for i in range(len(list_of_data)):\n",
        "#data_final=pd.concat([data,list_of_data[i]])\n",
        "data_final=pd.concat(list_of_data, axis=1).fillna(0)\n",
        "#print(data_final)\n",
        "c=pd.concat([data, data_final], axis=1).fillna(0)\n",
        "#print(data.shape)\n",
        "print(c)\n",
        "c=c.drop(columns=[\"cut\", \"color\", \"clarity\",\"depth\", \"table\", \"x\", \"y\", \"z\"])\n",
        "c.rename(columns={'Very Good':'Very_Good'}, inplace=True)\n",
        "print(c.columns)\n",
        "trainFraction = .75\n",
        "sample = np.random.uniform(size = 53940) < trainFraction\n",
        "trainingDat = c[sample]\n",
        "testingDat = c[~sample]\n",
        "\n",
        "Y=trainingDat['price']\n",
        "X=trainingDat.drop(columns='price')\n",
        "X_test=testingDat.drop(columns='price')\n",
        "Y_test=testingDat['price']\n",
        "X_test=X_test.assign(carat_norm=normalize(X_test.carat))\n",
        "X_test=X_test.drop(columns='carat')\n",
        "#X_test=normalize(X_test)\n",
        "\n",
        "X=X.assign(carat_norm=normalize(X.carat))\n",
        "X=X.drop(columns='carat')\n",
        "\n",
        "#Y_test=normalize(Y_test)\n",
        "\n",
        "Y = pd.DataFrame.to_numpy(Y)\n",
        "X = pd.DataFrame.to_numpy(X)\n",
        "Y_test = pd.DataFrame.to_numpy(Y_test)\n",
        "X_test = pd.DataFrame.to_numpy(X_test)\n",
        "X = torch.from_numpy(X).float()\n",
        "X_test= torch.from_numpy(X_test).float()\n",
        "Y=torch.from_numpy(Y).float()\n",
        "Y_test=torch.from_numpy(Y_test).float()\n",
        "print(X.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       carat        cut color clarity  ...  Good  Ideal  Premium  Very Good\n",
            "0       0.23      Ideal     E     SI2  ...     0      1        0          0\n",
            "1       0.21    Premium     E     SI1  ...     0      0        1          0\n",
            "2       0.23       Good     E     VS1  ...     1      0        0          0\n",
            "3       0.29    Premium     I     VS2  ...     0      0        1          0\n",
            "4       0.31       Good     J     SI2  ...     1      0        0          0\n",
            "...      ...        ...   ...     ...  ...   ...    ...      ...        ...\n",
            "53935   0.72      Ideal     D     SI1  ...     0      1        0          0\n",
            "53936   0.72       Good     D     SI1  ...     1      0        0          0\n",
            "53937   0.70  Very Good     D     SI1  ...     0      0        0          1\n",
            "53938   0.86    Premium     H     SI2  ...     0      0        1          0\n",
            "53939   0.75      Ideal     D     SI2  ...     0      1        0          0\n",
            "\n",
            "[53940 rows x 27 columns]\n",
            "Index(['carat', 'price', 'E', 'F', 'G', 'H', 'I', 'J', 'IF', 'SI1', 'SI2',\n",
            "       'VS1', 'VS2', 'VVS1', 'VVS2', 'Good', 'Ideal', 'Premium', 'Very_Good'],\n",
            "      dtype='object')\n",
            "torch.Size([40327, 18])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeGb2A1Z0ulQ"
      },
      "source": [
        "\n",
        "model=torch.nn.Sequential(torch.nn.Linear(18,3), torch.nn.ReLU(), torch.nn.Linear(3,1))\n",
        "model=model.cuda()\n",
        "loss_function = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_cUnxgm1am8",
        "outputId": "bd3078c5-a217-482f-847c-f682fc56e9dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "\n",
        "for i in range(5000):\n",
        "  y_pred=model(X)\n",
        "  loss=loss_function(y_pred, Y)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  print(i)\n",
        "  optimizer.step()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([40327])) that is different to the input size (torch.Size([40327, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c7902b8f2ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-9DhhUC8zAf",
        "outputId": "881ddf24-fbc4-4ad1-baa1-b4592069479b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!install pip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "install: missing destination file operand after 'pip'\n",
            "Try 'install --help' for more information.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqcazgNv7s26"
      },
      "source": [
        "pip install --upgrade jupyter_http_over_ws>=0.0.7 && \\\n",
        "  jupyter serverextension enable --py jupyter_http_over_ws"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or8JMnyrUgvY"
      },
      "source": [
        ""
      ]
    }
  ]
}